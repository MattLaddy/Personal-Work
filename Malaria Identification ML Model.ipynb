from google.colab import drive 
drive.mount('/content/drive')


import tensorflow as tf
import math
import numpy as np # the fundamental building block of ML: arrays!
import matplotlib.pyplot as plt # this will help us plot and visualize our data
import logging
import seaborn as sns # this will help us in understanding performance metrics towards the end

!pip install -U tensorflow_datasets # we're getting the repository of datasets that this project's dataset belongs to

import tensorflow_datasets as tfds 
tfds.disable_progress_bar()

logger = tf.get_logger()
logger.setLevel(logging.ERROR)

# We will use these variables for visualization of the dataset later.
ds, info = tfds.load('malaria', split='train', shuffle_files=False, with_info=True)


# We will use these variables for actually training the model.
train_ds, test_ds = tfds.load(
  'malaria',
  split = ['train[:65%]', 'train[65%:]'],
  shuffle_files= False, as_supervised = True,
)

NUM_TRAIN_IMAGES = tf.data.experimental.cardinality(train_ds).numpy()


NUM_TEST_IMAGES = tf.data.experimental.cardinality(test_ds).numpy()
#prints the number train then test
print(NUM_TRAIN_IMAGES)
print(NUM_TEST_IMAGES)


vis = tfds.visualization.show_examples(ds, info)


for image, label in train_ds.take(2):
    print("Image size: ", image.numpy().shape)
    print("Label: ", label.numpy())
    
    
    BATCH_SIZE = 32
IMAGE_SIZE = [200, 200]


# DO NOT MODIFY THIS FUNCTION
def convert(image, label):
  image = tf.image.convert_image_dtype(image, tf.float32)
  return image, label


# resizing each image to 200 x 200
def pad(image,label): 
  image,label = convert(image, label)
  image = tf.image.resize_with_crop_or_pad(image,200,200)
  return image, label

# switching the 0 and 1 around, as mentioned
def invert_labels(image, label):

#Possible Solution
  if label == 1:
    label = 0 ;
  else:
    label=1
  return image, label


# DO NOT MODIFY CODE BELOW
clean_train_ds = (
    train_ds
    .map(pad)
    .map(invert_labels)
)

clean_test_ds = (
    test_ds
    .map(pad)
    .map(invert_labels)
) 



image_batch, label_batch = next(iter(clean_train_ds.batch(BATCH_SIZE)))

def show_batch(image_batch, label_batch):
    plt.figure(figsize = (10, 10))
    for n in range(25):
        ax = plt.subplot(5, 5, n+1)
        plt.imshow(image_batch[n])
        if label_batch[n]:
            plt.title("parasitized (1) ")
        else:
            plt.title("uninfected (0) ")
        plt.axis("off")
show_batch(image_batch.numpy(), label_batch.numpy())

clean_train_ds = clean_train_ds.repeat().shuffle(NUM_TRAIN_IMAGES).batch(BATCH_SIZE)
clean_test_ds = clean_test_ds.batch(BATCH_SIZE)

model = tf.keras.Sequential([
                             
    tf.keras.layers.Conv2D(32, (3, 3), padding = 'same', activation = tf.nn.relu, input_shape = (200, 200, 3)),
    tf.keras.layers.MaxPooling2D((2, 2), strides = 2),

    tf.keras.layers.Conv2D(32, (3, 3), padding = 'same', activation = tf.nn.relu),
    tf.keras.layers.MaxPooling2D((2, 2), strides = 2),

    # BUILD YOUR PART HERE (Dense and output layers):


    tf.keras.layers.Flatten(),
   #input layer needs 200x200 nodes = 40000,
    tf.keras.layers.Dense(500,activation = 'tanh'),
    tf.keras.layers.Dense(32,activation = 'tanh'),
    tf.keras.layers.Dense(32, activation ='tanh'),
    tf.keras.layers.Dense(10, activation ='tanh'),
    tf.keras.layers.Dense(1,activation = 'sigmoid'),

])

model.summary() # this is going to print a quick little summary of our model


#optmizer can change later, and can change learining rate
optimizerIn = tf.keras.optimizers.Adam()




#dont change loss
lossIn = tf.keras.losses.BinaryCrossentropy()

#compilier
model.compile(optimizer = optimizerIn,
              loss=lossIn,
              metrics = [tf.keras.metrics.TruePositives(), tf.keras.metrics.TrueNegatives(), tf.keras.metrics.FalsePositives(), tf.keras.metrics.FalseNegatives()])

NUMBER_OF_EPOCHS = 5
BATCH_SIZE = 32
steps = NUM_TRAIN_IMAGES/BATCH_SIZE
print(steps)
# YOUR CODE GOES HERE


model.fit(clean_train_ds, epochs=NUMBER_OF_EPOCHS, batch_size=BATCH_SIZE, steps_per_epoch=steps)

test_loss, test_tp, test_tn, test_fp, test_fn = model.evaluate(clean_test_ds, steps = math.ceil(NUM_TEST_IMAGES/BATCH_SIZE))


def draw_confusion_matrix(tp, tn, fp, fn):
  cf_matrix = np.array([[tp, fp], [fn, tn]])
  group_names = ['True Pos','False Pos','False Neg','True Neg']
  group_counts = ["{0:0.0f}".format(value) for value in cf_matrix.flatten()]
  group_percentages = ["{0:.2%}".format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)]
  labels = [f"{v1}\n{v2}\n{v3}" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]
  labels = np.asarray(labels).reshape(2,2)
  sns.heatmap(cf_matrix, annot = labels, fmt = '', cmap = 'Blues', xticklabels = False, yticklabels = False)
  
  
  draw_confusion_matrix(test_tp, test_tn, test_fp, test_fn)
